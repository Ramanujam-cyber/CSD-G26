{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## Notebook for Testing Fine-tuned Sentiment Model\n",
        "\n",
        "# @title Cell 1: Install Libraries\n",
        "!pip install transformers torch pandas emoji -q\n",
        "print(\"Libraries installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKzxI6ukzW25",
        "outputId": "c3fb37d6-4d91-43c6-8175-647ad9b5f1cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 2: Import Libraries\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import emoji\n",
        "from google.colab import drive\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "id": "MBNYyeKtzit5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ae9e8a-2d23-4818-e395-bd169afbe1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU_MLlJP2eKe",
        "outputId": "d1f98e50-e589-4136-8819-221063999786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 3: Get Model from Google Drive\n",
        "\n",
        "# --- Mount Google Drive ---\n",
        "try:\n",
        "    print(\"Mounting Google Drive...\")\n",
        "    drive.mount('/content/drive', force_remount=True) # force_remount can help if Drive connection issues occur\n",
        "    print(\"Google Drive mounted successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error mounting Google Drive: {e}\")\n",
        "    raise SystemExit(\"Mounting failed.\")\n",
        "\n",
        "# --- *** IMPORTANT: SET THIS PATH *** ---\n",
        "# Path to the ZIP file WITHIN your Google Drive.\n",
        "# Example: /content/drive/MyDrive/Model07/your_model_file.zip\n",
        "zip_path_in_drive = \"/content/drive/MyDrive/Model07/distilbert-base-uncased_50000subset_3epochs.zip\" # <<< CHANGE to the correct path in YOUR Drive\n",
        "\n",
        "# Path where the unzipped model folder should be created IN COLAB\n",
        "# This path will be used in the next cell to load the model\n",
        "model_path_in_colab = \"/content/fine_tuned_sentiment_model\"\n",
        "# --- ---\n",
        "\n",
        "# --- Unzip the model from Drive to Colab ---\n",
        "try:\n",
        "    if not os.path.exists(zip_path_in_drive):\n",
        "        print(f\"ERROR: Zip file not found at: {zip_path_in_drive}\")\n",
        "        print(\"Please ensure you saved a copy to your Drive and the path is correct.\")\n",
        "        raise FileNotFoundError(\"Zip file not found in Drive.\")\n",
        "\n",
        "    print(f\"Unzipping model from {zip_path_in_drive} to {model_path_in_colab}...\")\n",
        "\n",
        "    # Create target directory if it doesn't exist\n",
        "    os.makedirs(model_path_in_colab, exist_ok=True)\n",
        "\n",
        "    # Unzip using the zipfile module for better control\n",
        "    with zipfile.ZipFile(zip_path_in_drive, 'r') as zip_ref:\n",
        "        zip_ref.extractall(model_path_in_colab)\n",
        "\n",
        "    # --- Check if the expected output directory exists after unzipping ---\n",
        "    extracted_folders = [f for f in os.listdir(model_path_in_colab) if os.path.isdir(os.path.join(model_path_in_colab, f))]\n",
        "    if len(extracted_folders) == 1:\n",
        "        # Assume the zip contained one folder with the model files\n",
        "        potential_model_path = os.path.join(model_path_in_colab, extracted_folders[0])\n",
        "        # Check if this subdirectory actually contains the config file\n",
        "        if os.path.exists(os.path.join(potential_model_path, \"config.json\")):\n",
        "             model_path_in_colab = potential_model_path\n",
        "             print(f\"Model files found in subdirectory: {model_path_in_colab}\")\n",
        "    elif not os.path.exists(os.path.join(model_path_in_colab, \"config.json\")):\n",
        "         print(f\"WARNING: config.json not found directly in {model_path_in_colab}.\")\n",
        "         print(\"Please check the unzipped contents and adjust 'model_path_in_colab' if needed before running the next cell.\")\n",
        "         print(f\"Contents of {model_path_in_colab}: {os.listdir(model_path_in_colab)}\")\n",
        "\n",
        "\n",
        "    print(f\"Model successfully unzipped to: {model_path_in_colab}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    # Error message printed above\n",
        "    pass\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during unzipping: {e}\")\n",
        "    raise SystemExit(\"Unzipping failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBUVQvsF30dm",
        "outputId": "9244a0d0-ae64-41c0-e0b1-f6e395dfb545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive mounted successfully.\n",
            "Unzipping model from /content/drive/MyDrive/Model07/distilbert-base-uncased_50000subset_3epochs.zip to /content/fine_tuned_sentiment_model...\n",
            "Model files found in subdirectory: /content/fine_tuned_sentiment_model/sentiment_model_amazon_csv_finetuned\n",
            "Model successfully unzipped to: /content/fine_tuned_sentiment_model/sentiment_model_amazon_csv_finetuned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 4: Load Model and Tokenizer\n",
        "\n",
        "print(\"--- Loading Model & Tokenizer ---\")\n",
        "\n",
        "if 'model_path_in_colab' not in locals():\n",
        "    # Default if Cell 3 wasn't run or variable got lost - adjust as needed\n",
        "    model_path_in_colab = \"/content/fine_tuned_sentiment_model/sentiment_model_amazon_csv_finetuned\" # Example path\n",
        "    print(f\"Warning: 'model_path_in_colab' not found, defaulting to {model_path_in_colab}. Ensure this is correct.\")\n",
        "    # raise SystemExit(\"Variable 'model_path_in_colab' not set. Please run Cell 3 first.\") # Option to halt instead\n",
        "\n",
        "saved_model_path = model_path_in_colab\n",
        "# --- ---\n",
        "\n",
        "try:\n",
        "    if not os.path.isdir(saved_model_path):\n",
        "        print(f\"ERROR: Directory not found: {saved_model_path}\")\n",
        "        print(\"Please ensure Cell 3 ran correctly, unzipped the file, and set the path correctly.\")\n",
        "        raise FileNotFoundError(\"Model directory not found.\")\n",
        "\n",
        "    print(f\"Loading tokenizer from: {saved_model_path}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
        "\n",
        "    print(f\"Loading model from: {saved_model_path}\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
        "\n",
        "    # Check if GPU is available and move model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "    print(f\"Model moved to device: {device}\")\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "    print(\"Model and tokenizer loaded successfully.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "     # Error message printed above\n",
        "     raise SystemExit(\"Loading failed.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred loading the model/tokenizer: {e}\")\n",
        "    print(f\"Please check if the path '{saved_model_path}' contains the necessary model files (config.json, model weights, tokenizer files).\")\n",
        "    raise SystemExit(\"Loading failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJE2p3_-38Bh",
        "outputId": "9d07c95f-fb88-4a05-8c26-d884abd6bae0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Loading Model & Tokenizer ---\n",
            "Loading tokenizer from: /content/fine_tuned_sentiment_model/sentiment_model_amazon_csv_finetuned\n",
            "Loading model from: /content/fine_tuned_sentiment_model/sentiment_model_amazon_csv_finetuned\n",
            "Model moved to device: cpu\n",
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5: Prediction Function (Emojis, No Probabilities - Modified)\n",
        "\n",
        "# Define sentiment mapping (using the Amazon model's 1-5 score)\n",
        "sentiment_map = {1: \"Score 1 (Very Negative)\", 2: \"Score 2 (Negative)\", 3: \"Score 3 (Neutral)\", 4: \"Score 4 (Positive)\", 5: \"Score 5 (Very Positive)\"}\n",
        "\n",
        "# MODIFIED: Function now takes model and tokenizer as input arguments\n",
        "# MODIFIED: Added emoji conversion step\n",
        "# MODIFIED: REMOVED probability calculation and printing\n",
        "def predict_sentiment(text, model_to_use, tokenizer_to_use):\n",
        "    \"\"\"Converts emojis, tokenizes text, predicts sentiment, and returns score/label.\"\"\"\n",
        "\n",
        "    print(f\"\\nOriginal Input Text: '{text}'\")\n",
        "    # Basic check for valid text input\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        print(\"Invalid input text provided.\")\n",
        "        return None, None\n",
        "    try:\n",
        "        # --- Convert emojis to text aliases ---\n",
        "        text_no_emoji = emoji.demojize(text, language='alias')\n",
        "        if text != text_no_emoji:\n",
        "             print(f\"Text after demojize: '{text_no_emoji}'\") # Show converted text if emojis were present\n",
        "        # --- ---\n",
        "\n",
        "        # Tokenize using the provided tokenizer\n",
        "        inputs = tokenizer_to_use(text_no_emoji, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
        "\n",
        "        # Move inputs to the same device as the provided model\n",
        "        inputs = {k: v.to(model_to_use.device) for k, v in inputs.items()}\n",
        "\n",
        "        # Perform prediction using the provided model\n",
        "        with torch.no_grad(): # Disable gradient calculation for inference\n",
        "            logits = model_to_use(**inputs).logits\n",
        "\n",
        "        # Get the predicted class index\n",
        "        predicted_class_id = torch.argmax(logits, dim=-1).item() # Argmax directly on logits\n",
        "\n",
        "        # Map back to original sentiment score (0-4 -> 1-5)\n",
        "        predicted_sentiment_score = predicted_class_id + 1\n",
        "        predicted_label = sentiment_map.get(predicted_sentiment_score, 'Unknown')\n",
        "\n",
        "        print(f\"Predicted Sentiment Score (1-5): {predicted_sentiment_score}\")\n",
        "        print(f\"Predicted Sentiment Label: {predicted_label}\")\n",
        "\n",
        "        # --- Probabilities section removed ---\n",
        "\n",
        "        return predicted_sentiment_score, predicted_label\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during prediction: {e}\")\n",
        "        return None, None\n",
        "\n",
        "print(\"Prediction function defined (converts emojis, requires model/tokenizer arguments\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkQUgd95Ir6v",
        "outputId": "54a983b2-d18f-484e-9259-e2b626787cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction function defined (converts emojis, requires model/tokenizer arguments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 5b: Load Test Dataset (Modified)\n",
        "\n",
        "# --- Configuration ---\n",
        "test_csv_path = \"/content/Social Media comments.csv\"\n",
        "\n",
        "test_text_column = \"Text\"\n",
        "\n",
        "num_samples_to_test = 10\n",
        "\n",
        "test_samples = []\n",
        "df_test = None\n",
        "\n",
        "# --- Inspect and Load Test Data ---\n",
        "print(f\"--- Processing Test Data ---\")\n",
        "try:\n",
        "    # Ensure pandas (pd) is available (Cell 2 should have run)\n",
        "    if 'pd' not in globals(): raise NameError(\"'pd' is not defined. Please run Cell 2 first.\")\n",
        "\n",
        "    if os.path.exists(test_csv_path):\n",
        "        print(f\"Inspecting Test data: {test_csv_path}\")\n",
        "        df_test_head = pd.read_csv(test_csv_path, nrows=5)\n",
        "        print(\"Test Data Columns:\", df_test_head.columns.tolist())\n",
        "        print(\"Test Data Head:\\n\", df_test_head.head())\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        if test_text_column not in df_test_head.columns:\n",
        "             print(f\"ERROR: Column '{test_text_column}' not found in {test_csv_path}.\")\n",
        "             print(\"Please UPDATE 'test_text_column' in this cell and rerun.\")\n",
        "        else:\n",
        "            print(f\"Loading Test samples from column '{test_text_column}'...\")\n",
        "            # Load full file (or handle large files differently if needed)\n",
        "            df_test = pd.read_csv(test_csv_path)\n",
        "            df_test = df_test.dropna(subset=[test_text_column])\n",
        "            # Take random samples\n",
        "            test_samples = df_test[test_text_column].sample(n=min(num_samples_to_test, len(df_test)), random_state=101).tolist()\n",
        "            print(f\"Loaded {len(test_samples)} Test samples.\")\n",
        "    else:\n",
        "        print(f\"Warning: Test file not found at {test_csv_path}\")\n",
        "\n",
        "except NameError as ne:\n",
        "    print(f\"ERROR: {ne}\")\n",
        "    print(\"Import failed? Run Cell 2.\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File not found: {test_csv_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error inspecting/loading Test data: {e}\")\n",
        "\n",
        "\n",
        "# --- Report loaded samples ---\n",
        "print(f\"\\nTotal Test samples loaded: {len(test_samples)}\")\n",
        "if not test_samples:\n",
        "     print(\"\\nWarning: No samples loaded from the test dataset.\")\n",
        "print(\"Ready for Cell 6.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0n0l20KI0dA",
        "outputId": "92f60bd2-57ee-4aef-c428-8b4cc6799512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Processing Test Data ---\n",
            "Inspecting Test data: /content/Social Media comments.csv\n",
            "Test Data Columns: ['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time', 'Summary', 'Text']\n",
            "Test Data Head:\n",
            "        Id   ProductId          UserId             ProfileName  \\\n",
            "0  165257  B000EVG8J2  A1L01D2BD3RKVO  B. Miller \"pet person\"   \n",
            "1  231466  B0000BXJIS  A3U62RE5XZDP0G                   Marty   \n",
            "2  427828  B008FHUFAU   AOXC0JQQZGGB6         Kenneth Shevlin   \n",
            "3  433955  B006BXV14E  A3PWPNZVMNX3PA             rareoopdvds   \n",
            "4   70261  B007I7Z3Z0  A1XNZ7PCE45KK7                  Og8ys1   \n",
            "\n",
            "   HelpfulnessNumerator  HelpfulnessDenominator        Time  \\\n",
            "0                     0                       0  1268179200   \n",
            "1                     0                       0  1298937600   \n",
            "2                     0                       2  1224028800   \n",
            "3                     0                       1  1335312000   \n",
            "4                     0                       2  1334707200   \n",
            "\n",
            "                                        Summary  \\\n",
            "0  Crunchy & Good Gluten-Free Sandwich Cookies!   \n",
            "1                            great kitty treats   \n",
            "2                                  COFFEE TASTE   \n",
            "3              So the Mini-Wheats were too big?   \n",
            "4                             Great Taste . . .   \n",
            "\n",
            "                                                Text  \n",
            "0  Having tried a couple of other brands of glute...  \n",
            "1  My cat loves these treats. If ever I can't fin...  \n",
            "2  A little less than I expected.  It tends to ha...  \n",
            "3  First there was Frosted Mini-Wheats, in origin...  \n",
            "4  and I want to congratulate the graphic artist ...  \n",
            "------------------------------\n",
            "Loading Test samples from column 'Text'...\n",
            "Loaded 10 Test samples.\n",
            "\n",
            "Total Test samples loaded: 10\n",
            "Ready for Cell 6.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cell 6: Test Predictions on Loaded Samples (Modified)\n",
        "\n",
        "print(\"\\n--- Running Test Predictions on Loaded Samples ---\")\n",
        "\n",
        "# Check if required variables exist before proceeding\n",
        "run_predictions = True\n",
        "if 'test_samples' not in locals():\n",
        "     print(\"ERROR: 'test_samples' list not found. Please run Cell 5b first.\")\n",
        "     run_predictions = False\n",
        "elif not test_samples:\n",
        "     print(\"Warning: 'test_samples' list is empty. No predictions to run.\")\n",
        "     run_predictions = False\n",
        "elif 'predict_sentiment' not in globals():\n",
        "     print(\"ERROR: predict_sentiment function not defined. Please run Cell 5 first.\")\n",
        "     run_predictions = False\n",
        "elif 'model' not in locals() or model is None:\n",
        "     print(\"ERROR: 'model' not loaded or is None. Please run Cell 4 successfully.\")\n",
        "     run_predictions = False\n",
        "elif 'tokenizer' not in locals() or tokenizer is None:\n",
        "     print(\"ERROR: 'tokenizer' not loaded or is None. Please run Cell 4 successfully.\")\n",
        "     run_predictions = False\n",
        "\n",
        "if run_predictions:\n",
        "    # Proceed if all checks pass\n",
        "    print(f\"Using loaded model and tokenizer for predictions on {len(test_samples)} samples...\")\n",
        "    for i, comment in enumerate(test_samples):\n",
        "        print(f\"\\n--- Sample {i+1} ---\")\n",
        "        # Pass model and tokenizer to the function\n",
        "        predict_sentiment(comment, model, tokenizer)\n",
        "else:\n",
        "    print(\"Cannot run predictions due to missing functions or variables.\")\n",
        "\n",
        "\n",
        "print(\"\\n--- Testing Finished ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4a2U-RAbJdqe",
        "outputId": "cbd897aa-c0c5-43b9-cd7d-c933e8125d92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Running Test Predictions on Loaded Samples ---\n",
            "Using loaded model and tokenizer for predictions on 10 samples...\n",
            "\n",
            "--- Sample 1 ---\n",
            "\n",
            "Original Input Text: 'I love coffee, I drink it two times per day/every day. I expected this coffee not to be so good because of a few bad reviews that I read but I like it. I would definitely buy it again (different type bec I want to try new things). I wouldn't say that this was the best coffee in the world ever but it was good for me. Definitely million times better than Folgers, Maxwell, Sam's Choice coffee's and the Kroger brand coffee-not as good as Starbucks but cheaper than Starbucks so I think it is a good buy.'\n",
            "Predicted Sentiment Score (1-5): 4\n",
            "Predicted Sentiment Label: Score 4 (Positive)\n",
            "\n",
            "--- Sample 2 ---\n",
            "\n",
            "Original Input Text: 'I read about it, I was really excited, I wanted so badly to like this stuff!<br />Truth is, it's just plain awful.'\n",
            "Predicted Sentiment Score (1-5): 1\n",
            "Predicted Sentiment Label: Score 1 (Very Negative)\n",
            "\n",
            "--- Sample 3 ---\n",
            "\n",
            "Original Input Text: 'These are wonderful for newborns, who don't drink large amounts.  Small nipples, so they fit the newborn mouths well, and no mixing during that overwhelming time when they are first born.  Save the nipples and rings so you can use them on new bottles, and recycle the empty bottles.  Also good for diaper bags for when the babies are small (and don't need large amounts yet).'\n",
            "Predicted Sentiment Score (1-5): 5\n",
            "Predicted Sentiment Label: Score 5 (Very Positive)\n",
            "\n",
            "--- Sample 4 ---\n",
            "\n",
            "Original Input Text: 'My first time experience Coconut Water. I heard it is good for inflammation. I am very happy with my choice of choosing ZICO.'\n",
            "Predicted Sentiment Score (1-5): 5\n",
            "Predicted Sentiment Label: Score 5 (Very Positive)\n",
            "\n",
            "--- Sample 5 ---\n",
            "\n",
            "Original Input Text: 'This is the strangest thing I've ever seen.  Imagine your roll on deodorant container  being filled with some bacon flavored  gravy and then allowing your dog to lick from it for his daily treat!  Are you kidding me?  This idea is gross and unsanitary and how do you get a dog to understand the concept that they are only supposed to take a few licks and that's their treat.  My dog kept trying to grab the container, she thought I was trying to tease her with it.  Finally I started rolling it on the dry milk bone type treats that she's not crazy about to get her to eat them.  If they called it \"Dog Bone Icing\" it might sell better  and make more sense.'\n",
            "Predicted Sentiment Score (1-5): 1\n",
            "Predicted Sentiment Label: Score 1 (Very Negative)\n",
            "\n",
            "--- Sample 6 ---\n",
            "\n",
            "Original Input Text: 'I'm not a big cereal eater, but I love this cereal.  It is perfect with Vanilla Coconut milk.  I bought it for my kids, but I think I like it even more than they do.'\n",
            "Predicted Sentiment Score (1-5): 5\n",
            "Predicted Sentiment Label: Score 5 (Very Positive)\n",
            "\n",
            "--- Sample 7 ---\n",
            "\n",
            "Original Input Text: 'My boxer likes these, but he doesn't get really excited about them.  But if they work as advertised and clean his teeth, then they are great.'\n",
            "Predicted Sentiment Score (1-5): 4\n",
            "Predicted Sentiment Label: Score 4 (Positive)\n",
            "\n",
            "--- Sample 8 ---\n",
            "\n",
            "Original Input Text: 'Disgusting, yuck, no thanks! The first three words I thought of after biting into one of these chocolate fruit tragedies. Buy something else, these are terrible.'\n",
            "Predicted Sentiment Score (1-5): 1\n",
            "Predicted Sentiment Label: Score 1 (Very Negative)\n",
            "\n",
            "--- Sample 9 ---\n",
            "\n",
            "Original Input Text: 'The Best Cat Litter For Your Money<br /><br />I don't buy this from Amazon as a certain chain brick 'n' mortar has a much better price, but wanted to comment on this litter. Given the (other) price, it's the best litter out there. It scoops easily, lasts a long time and is just plain a good value. The other value brand that comes in the bright yellow pail is its closest competitor in price and I find it very had to scoop. This is so much easier.'\n",
            "Predicted Sentiment Score (1-5): 5\n",
            "Predicted Sentiment Label: Score 5 (Very Positive)\n",
            "\n",
            "--- Sample 10 ---\n",
            "\n",
            "Original Input Text: 'My 87 year old mother loves this soup, too-she has 1/2 can everyday for lunch. Recently supermarkets in our area stopped carrying it-I find it hard to believe it was due to lack of sales. Decided to see if I could purchase thru Amazon-luckily they have a nice package deal & I set up for the subscription every month (which works out price-wise to what I was paying in store). My sister called Campbells directly & they told her of a supermarket which was still carrying it but was about 25 miles away!! Thanks for coming to our rescue, Amazon. I'll be getting my first shipment soon.'\n",
            "Predicted Sentiment Score (1-5): 5\n",
            "Predicted Sentiment Label: Score 5 (Very Positive)\n",
            "\n",
            "--- Testing Finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Manual Tests ---\")\n",
        "predict_sentiment(\"The product is okay, not great but not terrible either.\", model, tokenizer)\n",
        "predict_sentiment(\"I guess it's fine for the price.\", model, tokenizer)\n",
        "predict_sentiment(\"A bit disappointed with the quality.\", model, tokenizer)\n",
        "predict_sentiment(\"Service could be improved.\", model, tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0xjWzvf7cvm",
        "outputId": "3f2d342d-1d3d-4992-d780-a4ec1fcba31e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Manual Tests ---\n",
            "\n",
            "Original Input Text: 'The product is okay, not great but not terrible either.'\n",
            "Predicted Sentiment Score (1-5): 3\n",
            "Predicted Sentiment Label: Score 3 (Neutral)\n",
            "\n",
            "Original Input Text: 'I guess it's fine for the price.'\n",
            "Predicted Sentiment Score (1-5): 4\n",
            "Predicted Sentiment Label: Score 4 (Positive)\n",
            "\n",
            "Original Input Text: 'A bit disappointed with the quality.'\n",
            "Predicted Sentiment Score (1-5): 3\n",
            "Predicted Sentiment Label: Score 3 (Neutral)\n",
            "\n",
            "Original Input Text: 'Service could be improved.'\n",
            "Predicted Sentiment Score (1-5): 5\n",
            "Predicted Sentiment Label: Score 5 (Very Positive)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 'Score 5 (Very Positive)')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}